{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgMyTMQiHunb14Wo14aayU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surabhi13gupta/LangChains/blob/main/LangChain_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azure.ai.inference\n",
        "!pip install azure.ai.inference.models\n",
        "!pip install azure.core.credentials"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXcJ1iRnoX8U",
        "outputId": "e19a288c-2cd7-40b5-cd34-dcd4318f2fa0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting azure.ai.inference\n",
            "  Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting isodate>=0.6.1 (from azure.ai.inference)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core>=1.30.0 (from azure.ai.inference)\n",
            "  Downloading azure_core-1.35.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from azure.ai.inference) (4.14.1)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure.ai.inference) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure.ai.inference) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure.ai.inference) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure.ai.inference) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure.ai.inference) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure.ai.inference) (2025.7.14)\n",
            "Downloading azure_ai_inference-1.0.0b9-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.35.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: isodate, azure-core, azure.ai.inference\n",
            "Successfully installed azure-core-1.35.0 azure.ai.inference-1.0.0b9 isodate-0.7.2\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement azure.ai.inference.models (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for azure.ai.inference.models\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement azure.core.credentials (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for azure.core.credentials\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.inference import ChatCompletionsClient\n",
        "from azure.ai.inference.models import SystemMessage, UserMessage\n",
        "from azure.core.credentials import AzureKeyCredential"
      ],
      "metadata": {
        "id": "4nicVhUIwZh4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "github_token = userdata.get('GITHUB_TOKEN')\n",
        "os.environ['GITHUB_TOKEN'] = github_token"
      ],
      "metadata": {
        "id": "HrqVlyAtouGD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = \"https://models.github.ai/inference\"\n",
        "model = \"openai/gpt-4.1\"\n",
        "token = os.environ[\"GITHUB_TOKEN\"]\n",
        "\n",
        "client = ChatCompletionsClient(\n",
        "    endpoint=endpoint,\n",
        "    credential=AzureKeyCredential(token),\n",
        ")\n",
        "\n",
        "response = client.complete(\n",
        "    messages=[\n",
        "        SystemMessage(\"You are a helpful assistant.\"),\n",
        "        UserMessage(\"What is the capital of France?\"),\n",
        "    ],\n",
        "    temperature=1.0,\n",
        "    top_p=1.0,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAyfhQnVoW61",
        "outputId": "c623b092-09e9-4f54-97d8-f1e6f30447e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "oWm9o-sqhIX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0dc3d9-ac5c-4465-9a06-c2e0716f08f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'choices': [{'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None, 'message': {'annotations': [], 'content': 'The capital of France is Paris.', 'refusal': None, 'role': 'assistant'}}], 'created': 1753332470, 'id': 'chatcmpl-Bwi9uuqBHwlWaLyE6EA1Gb4RERf70', 'model': 'gpt-4.1-2025-04-14', 'object': 'chat.completion', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'system_fingerprint': 'fp_07e970ab25', 'usage': {'completion_tokens': 8, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens': 24, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}, 'total_tokens': 32}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Response has more information and not just text"
      ],
      "metadata": {
        "id": "0cQt3oVbwp2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__AVk6x4woKF",
        "outputId": "4a60344b-3e0d-4083-dc2a-b989360a83f0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['choices', 'created', 'id', 'model', 'object', 'prompt_filter_results', 'system_fingerprint', 'usage'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response['choices'][0]['message']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6FpZw-3ww_T",
        "outputId": "4c988a9e-d0fb-4113-be4b-96683bd227db"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'annotations': [], 'content': 'The capital of France is Paris.', 'refusal': None, 'role': 'assistant'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response['choices'][0]['message']['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ChObKTc_w5ou",
        "outputId": "1cd2371e-bffb-4186-d0fc-5da46f74e08b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of France is Paris.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_creative = response = client.complete(\n",
        "    messages=[\n",
        "        SystemMessage(\"You are a helpful assistant.\"),\n",
        "        UserMessage(\"Poem on cricket\"),\n",
        "    ],\n",
        "    temperature=0.2,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "Y8v0J47MxWev"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_creative['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7SgZ2UTxfSZ",
        "outputId": "87979555-3fc6-4de9-87b5-745c6a00c214"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Here’s a poem on cricket:\n",
            "\n",
            "**The Gentleman's Game**\n",
            "\n",
            "Beneath the sun’s relentless gaze,  \n",
            "On fields of emerald green,  \n",
            "Eleven men in whites arrayed,  \n",
            "Their hopes and dreams unseen.\n",
            "\n",
            "The bowler’s run, the batter’s stance,  \n",
            "A hush falls on the crowd,  \n",
            "The leather ball, the willow’s dance,  \n",
            "The cheers erupting loud.\n",
            "\n",
            "A flick, a drive, a soaring six,  \n",
            "The scoreboard ticking fast,  \n",
            "A cunning spin, a clever trick,  \n",
            "The bails go flying past.\n",
            "\n",
            "The slip’s sharp catch, the keeper’s dive,  \n",
            "The fielder’s sprinting feet,  \n",
            "Each moment makes the game alive,  \n",
            "With glory and defeat.\n",
            "\n",
            "From village greens to stadium lights,  \n",
            "The spirit stays the same—  \n",
            "A battle fought in days and nights,  \n",
            "The love for cricket’s name.\n",
            "\n",
            "So here’s to every run and wicket,  \n",
            "To passion, pride, and fame,  \n",
            "For in our hearts, there’s always cricket—  \n",
            "The ever-gentleman’s game.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_deterministic = response = client.complete(\n",
        "    messages=[\n",
        "        SystemMessage(\"You are a helpful assistant.\"),\n",
        "        UserMessage(\"Poem on cricket\"),\n",
        "    ],\n",
        "    temperature=1.0,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "GvHJ6y84xhQe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_deterministic['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRKF1B5Fxrdp",
        "outputId": "c9712954-4033-49e8-f081-ba85296c0d93"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Here’s a poem on cricket:\n",
            "\n",
            "**Cricket’s Call**\n",
            "\n",
            "Beneath a sunlit, endless sky,  \n",
            "Where green and white in colors lie,  \n",
            "The field awakens, restless, bright,  \n",
            "As willow dreams meet leather’s flight.\n",
            "\n",
            "The bowler charges, fierce and bold,  \n",
            "A tale of pace, a story told.  \n",
            "The batsman waits with measured calm,  \n",
            "One instant’s clash between the palm.\n",
            "\n",
            "The ball spins secrets through the air;  \n",
            "A swing, a miss, the crowd’s loud prayer.  \n",
            "An edge, a sweep, the umpire’s hand—  \n",
            "Destiny drawn in dust and sand.\n",
            "\n",
            "The boundary roars, a six in flight,  \n",
            "New hopes reborn in searing light.  \n",
            "The fielders dart with eagle’s eyes,  \n",
            "While passion echoes with the cries.\n",
            "\n",
            "Tea break brings its gentle pause,  \n",
            "A time to ponder, mend, and cause  \n",
            "A thousand dreams to take their form,  \n",
            "In calm before the brewing storm.\n",
            "\n",
            "As shadows stretch and stumps arise,  \n",
            "The victors smile, the vanquished sighs.  \n",
            "Yet in the heart, a bond persists—  \n",
            "For cricket’s magic still exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_restricted = response = client.complete(\n",
        "    messages=[\n",
        "        SystemMessage(\"You are a helpful assistant.\"),\n",
        "        UserMessage(\"Poem on cricket\"),\n",
        "    ],\n",
        "    temperature=0.1,\n",
        "    max_tokens=20,\n",
        "    model=model\n",
        ")"
      ],
      "metadata": {
        "id": "QKOXdEA8x5OB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_restricted['choices'][0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI-ZeYsIx92I",
        "outputId": "e7e2a054-6942-4d9e-a2cc-011cfb28b38d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Here’s a poem on cricket:\n",
            "\n",
            "**The Gentleman's Game**\n",
            "\n",
            "Beneath the sun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Above shows limited token because max_token is set to 20"
      ],
      "metadata": {
        "id": "3K919Uy7yIHz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7H03_LTPyL1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}